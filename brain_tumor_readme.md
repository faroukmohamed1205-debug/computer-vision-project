# Brain Tumor Segmentation: Enhanced Pipeline with Advanced Preprocessing & Optimization

**A state-of-the-art deep learning project implementing brain tumor segmentation using ResUNet with advanced preprocessing, heavy augmentation, and Optuna-based hyperparameter optimization.**

## ğŸ¯ Project Overview

This project implements a complete **production-ready pipeline** featuring:
- **Advanced Preprocessing**: Bias Field Correction, CLAHE enhancement, Z-Score normalization
- **Heavy Data Augmentation**: Elastic transforms, Gaussian noise, spatial transforms
- **Baseline Model**: ResUNet with standard Tversky Loss (alpha=0.5, beta=0.5)
- **Optimized Model**: Hyperparameters tuned via Optuna using enhanced preprocessing

**Key Features:**
- âœ… **Advanced Image Preprocessing** - Bias correction, CLAHE, Z-score normalization
- âœ… **Heavy Data Augmentation** - Elastic transforms, noise, affine transformations
- âœ… **PyTorch Implementation** - Native PyTorch with DataLoader and nn.Module
- âœ… **Patient-wise Data Splitting** - No data leakage between train/val/test
- âœ… **ResUNet Architecture** - Residual connections for deep networks
- âœ… **Tversky Loss** - Optimized for imbalanced medical imaging data
- âœ… **Optuna Hyperparameter Optimization** - Automated search with TPE sampler
- âœ… **Publication-Ready Visualizations** - Professional figures for papers
- âœ… **Comprehensive Statistical Analysis** - Paired t-tests and performance metrics

## ğŸ“ Project Structure

```
brain_tumor_segmentation/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset_enhanced.py         # Enhanced data loading with preprocessing
â”‚   â”œâ”€â”€ preprocessing.py            # Bias correction, CLAHE, Z-score normalization
â”‚   â”œâ”€â”€ augmentation.py             # Light & heavy augmentation modes
â”‚   â”œâ”€â”€ model_utils.py              # ResUNet, Tversky Loss, metrics
â”‚   â””â”€â”€ paper_plots.py              # Publication-ready visualizations
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ brain_tumor_notebook_enhanced.ipynb  # Complete enhanced pipeline
â”‚   â”œâ”€â”€ preproc_augmentation_visualization.ipynb  # Preprocessing & augmentation demo
â”‚   â””â”€â”€ Project_Walkthrough.ipynb            # Original walkthrough
â”œâ”€â”€ data/
â”‚   â””â”€â”€ kaggle_3m/                  # Dataset (download from Kaggle separately)
â”œâ”€â”€ models/                         # Saved model checkpoints (auto-generated)
â”‚   â”œâ”€â”€ baseline_enhanced_model.pth
â”‚   â””â”€â”€ optimized_enhanced_model.pth
â”œâ”€â”€ results/                        # Generated results (auto-created)
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â”œâ”€â”€ patient_split.png
â”‚   â”‚   â”œâ”€â”€ slice_distribution.png
â”‚   â”‚   â”œâ”€â”€ enhanced_sample_batch.png
â”‚   â”‚   â”œâ”€â”€ preprocessing_comparison.png
â”‚   â”‚   â”œâ”€â”€ augmentation_examples.png
â”‚   â”‚   â”œâ”€â”€ training_curves_enhanced.png
â”‚   â”‚   â”œâ”€â”€ optuna_optimization_enhanced.png
â”‚   â”‚   â”œâ”€â”€ contest_results_enhanced.png
â”‚   â”‚   â””â”€â”€ model_comparison_enhanced.png
â”‚   â”œâ”€â”€ preprocessing/              # Preprocessing visualizations
â”‚   â”œâ”€â”€ augmentation/               # Augmentation visualizations
â”‚   â””â”€â”€ results_summary_enhanced.txt  # Text summary
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ config.py                       # Configuration constants
â”œâ”€â”€ setup.py                        # Project setup script
â””â”€â”€ README.md                       # This file
```

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone or download this project
git clone <your-repo-url>
cd brain_tumor_segmentation

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install PyTorch (with CUDA support if you have GPU)
# For CUDA 11.8:
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Or visit https://pytorch.org for your specific CUDA version

# Install other dependencies
pip install -r requirements.txt
```

**Note**: If you don't have a GPU, PyTorch will automatically use CPU (slower but functional).

### 2. Dataset Preparation

Download the LGG-MRI Segmentation Dataset from Kaggle:
- Dataset: [LGG MRI Segmentation](https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation)

Extract to `data/kaggle_3m/` directory:
```
data/
  â””â”€â”€ kaggle_3m/
      â”œâ”€â”€ TCGA_CS_4941_19960909/
      â”‚   â”œâ”€â”€ TCGA_CS_4941_19960909_1.tif
      â”‚   â”œâ”€â”€ TCGA_CS_4941_19960909_1_mask.tif
      â”‚   â””â”€â”€ ...
      â”œâ”€â”€ TCGA_CS_4942_19970222/
      â””â”€â”€ ... (100+ patient folders)
```

**Dataset Info:**
- 110 LGG patients
- 3,929 brain MRI slices total
- Binary segmentation (tumor vs background)
- High-quality annotations

### 3. Run the Project

```bash
# Launch the enhanced pipeline notebook
jupyter notebook notebooks/brain_tumor_notebook_enhanced.ipynb

# Or run preprocessing/augmentation demo
jupyter notebook notebooks/preproc_augmentation_visualization.ipynb

# Or run original walkthrough
jupyter notebook notebooks/Project_Walkthrough.ipynb
```

**Recommended**: Start with `brain_tumor_notebook_enhanced.ipynb` for the complete pipeline.

## ğŸ“Š Key Results

The enhanced pipeline generates comprehensive results:

### Visualizations Generated:
1. **Patient Distribution** - Pie chart showing 70/15/15 train/val/test split
2. **Slice Distribution** - Bar charts of tumor vs non-tumor across splits
3. **Preprocessing Comparison** - Original vs bias-corrected vs CLAHE-enhanced images
4. **Augmentation Examples** - Light vs heavy augmentation transformations
5. **Enhanced Sample Batch** - Real preprocessed & augmented training samples
6. **Training Curves** - Loss and Dice metrics for baseline vs optimized models
7. **Segmentation Contest** - Side-by-side visual comparisons of predictions
8. **Optuna Optimization** - Hyperparameter search and trial history
9. **Statistical Comparison** - Boxplot of per-sample Dice scores with statistics

### Pipeline Configuration:
```python
# Advanced Preprocessing
USE_BIAS_CORRECTION = True     # MRI intensity inhomogeneity correction
USE_CLAHE = True               # Contrast-Limited Adaptive Histogram Equalization
USE_ZSCORE = True              # Standardization to zero mean, unit variance

# Heavy Augmentation
AUGMENT_MODE = 'heavy'         # Elastic transforms, Gaussian noise, affine
BATCH_SIZE = 16
TARGET_SIZE = (256, 256)
NUM_WORKERS = 0                # Set for Windows compatibility
```

### Expected Performance:
- **Baseline Model**: Trained with enhanced preprocessing only
- **Optimized Model**: Further improved via Optuna hyperparameter search
- **Typical Improvement**: 3-8% relative increase in Dice coefficient
- **Test Dice Range**: 0.70-0.85 depending on data and hyperparameters

## ğŸ—ï¸ Pipeline Architecture

### 1. **Data Preprocessing Pipeline**

#### Bias Field Correction (N4ITK)
- Corrects MRI intensity inhomogeneity artifacts
- Improves consistency across different scanners

#### CLAHE (Contrast-Limited Adaptive Histogram Equalization)
- Enhances local contrast without over-amplifying noise
- Better feature visibility for tumor regions

#### Z-Score Normalization
- Standardizes images to zero mean, unit variance
- Improves neural network training stability

**Result**: Cleaner, more consistent input images for model training

### 2. **Data Augmentation Pipeline**

#### Light Mode:
- Random horizontal/vertical flips
- Random 90Â° rotations
- Small random crops

#### Heavy Mode (Used in final pipeline):
- Elastic deformations
- Gaussian noise injection
- Affine transformations (rotation, scaling, shearing)
- Random brightness/contrast adjustments
- Combination of multiple transforms

**Result**: Robust models that generalize better to unseen data

### 3. **Model Architecture: ResUNet**

```
Input (256Ã—256Ã—3)
    â†“
[Encoder: 4 residual blocks with downsampling]
    32 â†’ 64 â†’ 128 â†’ 256 â†’ 512 filters
    â†“
[Bridge: 1 residual block]
    512 filters
    â†“
[Decoder: 4 residual blocks with upsampling + skip connections]
    512 â†’ 256 â†’ 128 â†’ 64 â†’ 32 filters
    â†“
[Output: Sigmoid activation]
    Output (256Ã—256Ã—1)
```

**Parameters**: ~31M (configurable via `filters_base`)
**Skip Connections**: Preserve spatial information from encoder
**Residual Blocks**: Enable training of very deep networks

### 4. **Loss Function: Tversky Loss**

For **imbalanced medical imaging** (most pixels are non-tumor):

```
Tversky Index = TP / (TP + alphaÂ·FN + betaÂ·FP)
Loss = 1 - Tversky Index
```

- **Alpha** (0.0-1.0): Weight of False Negatives
  - High Î±: Penalize missed tumors more
  - Low Î±: Allow missing small tumors
  
- **Beta** (0.0-1.0): Weight of False Positives
  - High Î²: Penalize false alarms more
  - Low Î²: More aggressive tumor detection

**Optimized Range**: Alpha and Beta both searched in [0.1, 0.9]

## ğŸ“ˆ Optimization Strategy

### Baseline Model Training
```python
# Configuration
Tversky Loss: alpha=0.5, beta=0.5
Optimizer: Adam(lr=1e-4)
Epochs: 30
Batch Size: 16
Early Stopping: patience=10

# Input Pipeline
- Advanced preprocessing (Bias Correction + CLAHE + Z-Score)
- Heavy augmentation (elastic transforms, noise)
```

### Hyperparameter Optimization with Optuna

**Search Space:**
- `alpha`: [0.1, 0.9] - Tversky FN weight
- `beta`: [0.1, 0.9] - Tversky FP weight  
- `learning_rate`: [1e-5, 1e-3] - Adam optimizer LR

**Search Algorithm:** TPE (Tree-structured Parzen Estimator)
**Objective Function:** Maximize validation Dice coefficient
**Number of Trials:** 20 (configurable)
**Parallel Evaluation:** Sequential (can be parallelized)

**Result:** Find optimal hyperparameters that work best with the enhanced preprocessing and augmentation pipeline

## ğŸ“ˆ Evaluation Metrics

- **Dice Coefficient**: Primary metric 
  ```
  Dice = 2Â·TP / (2Â·TP + FP + FN)
  ```
  - Range: 0-1 (1 = perfect overlap)
  - Especially good for imbalanced data
  
- **IoU (Jaccard Index)**: Secondary metric
  ```
  IoU = TP / (TP + FP + FN)
  ```
  - Range: 0-1 (1 = perfect intersection)
  - More conservative than Dice
  
- **Tversky Loss**: Training objective function
  ```
  Loss = 1 - TI where TI = TP / (TP + alphaÂ·FN + betaÂ·FP)
  ```
  
- **Binary Accuracy**: Pixel-wise classification accuracy
  ```
  Accuracy = (TP + TN) / (TP + TN + FP + FN)
  ```

## ğŸ“‹ Expected Outputs

After running the complete enhanced pipeline, you'll have:

```
models/
â”œâ”€â”€ baseline_enhanced_model.pth      # Best baseline with enhanced preprocessing
â”œâ”€â”€ optimized_enhanced_model.pth     # Best optimized model from Optuna
â””â”€â”€ trial_*.pth                      # Checkpoint from each Optuna trial

results/
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ patient_split.png               # Train/val/test split visualization
â”‚   â”œâ”€â”€ slice_distribution.png          # Tumor vs non-tumor distribution
â”‚   â”œâ”€â”€ preprocessing_comparison.png    # Original vs enhanced preprocessing
â”‚   â”œâ”€â”€ augmentation_mode_comparison.png # Light vs heavy augmentation
â”‚   â”œâ”€â”€ heavy_augmentation_examples.png # Heavy aug sample variations
â”‚   â”œâ”€â”€ enhanced_sample_batch.png       # Real training batch with preprocessing
â”‚   â”œâ”€â”€ optuna_optimization_enhanced.png # Hyperparameter search progress
â”‚   â”œâ”€â”€ training_curves_enhanced.png    # Loss & Dice curves (baseline vs optimized)
â”‚   â”œâ”€â”€ contest_results_enhanced.png    # Side-by-side predictions (5 samples)
â”‚   â””â”€â”€ model_comparison_enhanced.png   # Boxplot of per-sample Dice scores
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ preprocessing_comparison.png    # Step-by-step preprocessing visualization
â”‚
â”œâ”€â”€ augmentation/
â”‚   â”œâ”€â”€ augmentation_mode_comparison.png
â”‚   â””â”€â”€ heavy_augmentation_examples.png
â”‚
â””â”€â”€ results_summary_enhanced.txt        # Text report with all metrics and configs
```

**Total Output Size**: ~200-500 MB (depending on model size and visualizations)

## ğŸ“ Citation & References

If you use this code in your research, please cite:

```bibtex
@software{brain_tumor_enhanced_2024,
  author = {Ibrahim, Ahmed},
  title = {Brain Tumor Segmentation with Enhanced ResUNet Pipeline},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/Ahmed-Ibrahim7780/brain-tumor-segmentation}
}
```

**Dataset Citation**:
```bibtex
@article{buda2019brain,
  title={Brain tumor segmentation and radiomics survival prediction: contribution to the brats challenge},
  author={Buda, Mateusz and Saha, Ashirbani and Mazurowski, Maciej A},
  journal={arXiv preprint arXiv:1903.02872},
  year={2019}
}
```

**Key Papers**:

1. **ResUNet for Medical Image Segmentation**
   - Zhang et al., "Deep Residual Networks with Dynamically Weighted Loss Functions for Supervised Sequence Labeling" (2016)

2. **Tversky Loss**
   - Salehi et al., "Tversky loss function for image segmentation using 3D fully convolutional deep networks" (2017)

3. **Optuna Hyperparameter Optimization**
   - Akiba et al., "Optuna: A Next-generation Hyperparameter Optimization Framework" (2019)

4. **CLAHE**
   - Zuiderveld, K., "Contrast limited adaptive histogram equalization" (1994)

5. **Brain Tumor Segmentation Benchmarks**
   - Menze et al., "The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)" (2015)

## ğŸ”— Related Projects & Resources

- **PyTorch**: https://pytorch.org/
- **Optuna**: https://optuna.org/
- **Medical Imaging in PyTorch**: https://github.com/Project-MONAI/MONAI
- **Brain Tumor Segmentation Challenge**: https://www.med.upenn.edu/cbica/brats/

## ğŸ“ Support & Contact

For issues, questions, or contributions:
- Open an issue on GitHub
- Contact: Ahmed Ibrahim (GitHub: Ahmed-Ibrahim7780)
- Email: your.email@example.com

## ğŸ“œ License

This project is licensed under the MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- **Dataset**: Mateusz Buda et al. (Kaggle LGG-MRI Segmentation)
- **Architecture**: ResUNet for Medical Image Segmentation
- **Optimization**: Optuna framework by Optuna team
- **Framework**: PyTorch by Meta AI
- **Image Processing**: OpenCV, NumPy, SciPy communities
- **Community**: PyTorch and medical imaging research communities

---

## ğŸ“Š Project Statistics

- **Total Code Files**: 7
- **Total Lines of Code**: ~2,000+
- **Python Version**: 3.8+
- **PyTorch Version**: 2.0+
- **Training Time**: ~1-3 hours (GPU), ~24 hours (CPU)
- **Dataset Size**: ~110 patients, 3,929 MRI slices
- **Model Parameters**: ~31M (ResUNet)
- **Typical GPU Memory**: 4-6 GB (RTX 3060+)

---

**â­ If you find this project useful, please star the repository!**

**Last updated**: December 2024 | **Status**: Complete & Production-Ready

## ğŸ› ï¸ Customization

### Modify Training Parameters

Edit `config.py` or modify in the notebook:
```python
# Data configuration
BATCH_SIZE = 16              # Increase for faster training (needs GPU memory)
TARGET_SIZE = (256, 256)     # Image resolution
EPOCHS = 30                  # Training epochs per model
LEARNING_RATE = 1e-4         # Initial Adam learning rate

# Data split
TRAIN_SIZE = 0.70            # 70% for training
VAL_SIZE = 0.15              # 15% for validation
TEST_SIZE = 0.15             # 15% for testing
RANDOM_SEED = 42             # For reproducibility

# Advanced preprocessing flags
USE_BIAS_CORRECTION = True   # MRI intensity correction
USE_CLAHE = True             # Contrast enhancement
USE_ZSCORE = True            # Normalization method
```

### Change Model Architecture

In `src/model_utils.py` or notebook:
```python
model = ResUNet(
    in_channels=3,           # RGB input
    out_channels=1,          # Binary segmentation (tumor/no-tumor)
    filters_base=32          # Base filters: increase for larger capacity
).to(device)

# Larger models: filters_base=64
# Smaller models: filters_base=16
```

### Optuna Optimization Configuration

In the notebook:
```python
# Configuration
n_trials = 20                # Number of trials (higher = better search)
timeout = 3600               # Max time per trial in seconds
show_progress_bar = True     # Show progress visualization

# Search ranges
alpha_range = (0.1, 0.9)     # False Negative weight range
beta_range = (0.1, 0.9)      # False Positive weight range
learning_rate_range = (1e-5, 1e-3)  # Learning rate range (log scale)

# Run optimization
study.optimize(objective, n_trials=20, show_progress_bar=True)
```

### Toggle Augmentation Mode

```python
AUGMENT_MODE = 'heavy'  # 'light' or 'heavy'

# Light: Flips, small rotations (faster, baseline)
# Heavy: Elastic transforms, noise, large affine transforms (more robust)
```

## ğŸ› Troubleshooting

### GPU Memory Issues

**Symptoms**: CUDA out of memory errors

**Solutions**:
```python
# 1. Reduce batch size
BATCH_SIZE = 8    # or 4 for 6GB GPU

# 2. Reduce model size
model = ResUNet(in_channels=3, out_channels=1, filters_base=16)

# 3. Clear GPU cache between trials
torch.cuda.empty_cache()

# 4. Reduce image resolution
TARGET_SIZE = (128, 128)  # or (192, 192)
```

### Slow Training on CPU

**Solutions**:
```bash
# 1. Verify PyTorch uses GPU
python -c "import torch; print(torch.cuda.is_available())"

# 2. Install CUDA-enabled PyTorch
# Visit https://pytorch.org/get-started/locally/
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# 3. Check GPU is recognized
nvidia-smi

# 4. Reduce batch size to fit GPU
BATCH_SIZE = 8
```

### Data Loading Issues

**Symptoms**: FileNotFoundError or dataset empty

**Solutions**:
```python
# 1. Verify dataset path
DATA_DIR = r'E:\Important Projects\easy\data\kaggle_3m'
import os
print(os.listdir(DATA_DIR))  # Should show patient folders

# 2. Check image files exist
import glob
files = glob.glob(os.path.join(DATA_DIR, '**/**.tif'), recursive=True)
print(f"Found {len(files)} TIFF files")

# 3. Verify correct data structure
# Should be: kaggle_3m/TCGA_*/TCGA_*.tif
```

### Windows Encoding Issues

**Symptoms**: UnicodeEncodeError when writing results

**Solution** (already fixed in notebook):
```python
# Always use UTF-8 encoding
with open('results_summary.txt', 'w', encoding='utf-8') as f:
    f.write(summary)
```

### Multiprocessing Issues on Windows

**Symptoms**: Errors when creating DataLoader with num_workers > 0

**Solution** (already fixed in notebook):
```python
# Use num_workers=0 on Windows
NUM_WORKERS = 0  # Sequential loading (slower but compatible)
# On Linux/Mac: NUM_WORKERS = 4
```

### Out of Disk Space

**Expected disk usage**:
- Models: ~500 MB each (~1 GB total for 2 models)
- Visualizations: ~100-200 MB
- Trial checkpoints: ~500 MB
- **Total**: ~2 GB recommended

**Solutions**:
```bash
# Delete trial checkpoints after optimization
rm models/trial_*.pth

# Delete preprocessing visualizations if not needed
rm results/preprocessing/*.png
```

## ğŸ“š Module Reference

### `src/preprocessing.py`
Advanced image preprocessing with bias correction and CLAHE.

**Classes**:
- `ImagePreprocessor`: Apply bias correction, CLAHE, Z-score normalization
- `MaskPreprocessor`: Binarize and resize masks

**Key Methods**:
```python
preprocessor = ImagePreprocessor(
    target_size=(256, 256),
    use_bias_correction=True,
    use_clahe=True,
    use_zscore=True
)
img = preprocessor.preprocess_from_path('path/to/image.tif')
```

### `src/augmentation.py`
Data augmentation with light and heavy modes.

**Classes**:
- `ImageAugmentor`: Apply transformations (flips, rotations, elastic deformations, noise)

**Modes**:
- `'light'`: Flips, 90Â° rotations (faster, baseline)
- `'heavy'`: Elastic transforms, Gaussian noise, affine (more robust)

### `src/model_utils.py`
Neural network architecture and training utilities.

**Classes**:
- `TverskyLoss`: Loss function with configurable alpha/beta
- `ResUNet`: U-Net with residual blocks

**Functions**:
- `train_model()`: Full training loop with early stopping
- `validate()`: Validation/test evaluation
- `dice_coefficient()`: Dice metric
- `iou_coefficient()`: IoU metric
- `calculate_dice_per_sample()`: Per-image Dice scores

### `src/paper_plots.py`
Publication-ready visualization functions.

**Functions**:
- `plot_training_history()`: Loss and Dice curves
- `plot_model_comparison_boxplot()`: Statistical comparison
- `visualize_segmentation_contest()`: Side-by-side predictions
- `plot_optuna_optimization()`: Hyperparameter search visualization
- `plot_patient_split()`: Data split pie chart
- `plot_slice_distribution()`: Tumor/non-tumor distribution

### `src/dataset_enhanced.py`
Data loading and preprocessing pipeline.

**Functions**:
- `load_data_paths()`: Find all images and masks
- `split_patients()`: Patient-wise train/val/test split
- `create_enhanced_data_loaders()`: PyTorch DataLoaders with preprocessing
- `analyze_dataset_distribution()`: Statistics on dataset balance
